{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91d3cd89-47c6-40be-b859-db9a0fa18f62",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa6a0f16-acba-41a4-8b45-37126a4df062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../Common/rly_final_movies.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9690ed5-bcb6-4c74-8546-d97582b6e3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"keywords\"] = df[\"keywords\"].fillna('')\n",
    "df[\"overview\"] = df[\"overview\"].fillna('')\n",
    "df[\"synopsis\"] = df[\"synopsis\"].fillna('')\n",
    "df[\"text\"] = df[\"overview\"] + \" \" + df[\"synopsis\"] + \" \" + df[\"keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ef9e89-4e64-4fb2-b176-17e29355a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df[\"text\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abed1410-5a28-4b5a-8eb0-620d0d3abc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = [word for word in text.lower().split() if word not in stop_words]\n",
    "    #words = [stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "texts = [preprocess(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa7370-6f59-4c0f-a557-a763a1218cf1",
   "metadata": {},
   "source": [
    "## Using the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76253c9b-8d6a-4415-ae9f-709039af75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "lda = LdaModel(corpus=corpus, num_topics=30, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dcd4e1a-9318-4c28-b6db-1f514f46fbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Topic                                      Top Keywords\n",
      "0       0                    story, based, team, world, new\n",
      "1       1                     road, trip, one, embark, find\n",
      "2       2              hollywood, actor, frank, oil, beings\n",
      "3       3                    town, small, rock, band, jesus\n",
      "4       4               alien, must, earth, fight, invasion\n",
      "5       5               france, paris, century, one, dragon\n",
      "6       6                          show, joe, cat, drug, tv\n",
      "7       7                  drug, police, bank, murder, gang\n",
      "8       8              life, wife, woman, husband, marriage\n",
      "9       9               christmas, dog, holiday, santa, eve\n",
      "10     10          agent, cia, secret, agency, intelligence\n",
      "11     11              school, high, college, life, friends\n",
      "12     12               angeles, los, game, two, california\n",
      "13     13                    war, world, mission, space, us\n",
      "14     14      africa, martial, australia, australian, arts\n",
      "15     15               based, witch, novel, protect, young\n",
      "16     16                family, young, park, gold, journey\n",
      "17     17                  20, worker, mike, social, tennis\n",
      "18     18       family, father, based, mother, relationship\n",
      "19     19  possession, based, young, investigation, demonic\n",
      "20     20                life, security, island, guard, one\n",
      "21     21                    dance, dancer, new, emily, max\n",
      "22     22                     love, woman, falls, new, york\n",
      "23     23                      love, life, two, lives, tale\n",
      "24     24          new, woman, relationship, murder, killer\n",
      "25     25    vampire, monster, mysterious, hospital, mental\n",
      "26     26                     shark, new, life, beach, find\n",
      "27     27           son, father, heart, national, destroyed\n",
      "28     28           fashion, singing, trainer, ireland, two\n",
      "29     29                world, must, superhero, new, based\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "topics = []\n",
    "for idx, topic in lda.print_topics(-1):\n",
    "    words = [word.split(\"*\")[1].strip().strip('\"') for word in topic.split(\" + \")]\n",
    "    topics.append([idx, \", \".join(words[:5])])\n",
    "\n",
    "df = pd.DataFrame(topics, columns=[\"Topic\", \"Top Keywords\"])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb4814a-5312-40bc-9bac-8af9283076a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import os\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda, corpus, dictionary)\n",
    "pyLDAvis.save_html(LDAvis_prepared, 'lda_visualization.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dd08bda-923c-4155-9c67-752fe81077b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst   Topic 0   Topic 1   Topic 2   Topic 3   Topic 4   Topic 5  \\\n",
      "0  tt0156812  0.000654  0.375615  0.000654  0.119675  0.000654  0.000654   \n",
      "1  tt0195945  0.000607  0.000607  0.224562  0.000607  0.000607  0.000607   \n",
      "2  tt0134983  0.000539  0.218176  0.000539  0.000539  0.000539  0.000539   \n",
      "3  tt0186975  0.035840  0.000375  0.185359  0.609671  0.000375  0.000375   \n",
      "4  tt0195234  0.000557  0.000557  0.000557  0.239240  0.022716  0.000557   \n",
      "\n",
      "    Topic 6   Topic 7   Topic 8  ...  Topic 20  Topic 21  Topic 22  Topic 23  \\\n",
      "0  0.000654  0.000654  0.000654  ...  0.000654  0.000654  0.000654  0.000654   \n",
      "1  0.000607  0.000607  0.000607  ...  0.000607  0.000607  0.000607  0.000607   \n",
      "2  0.000539  0.000539  0.000539  ...  0.000539  0.000539  0.000539  0.000539   \n",
      "3  0.000375  0.000375  0.000375  ...  0.000375  0.000375  0.000375  0.000375   \n",
      "4  0.106732  0.000557  0.000557  ...  0.000557  0.000557  0.000557  0.000557   \n",
      "\n",
      "   Topic 24  Topic 25  Topic 26  Topic 27  Topic 28  Topic 29  \n",
      "0  0.000654  0.000654  0.000654  0.000654  0.000654  0.000654  \n",
      "1  0.000607  0.000607  0.000607  0.000607  0.141392  0.301664  \n",
      "2  0.000539  0.000539  0.000539  0.000539  0.000539  0.000539  \n",
      "3  0.000375  0.093809  0.000375  0.000375  0.000375  0.025926  \n",
      "4  0.046686  0.000557  0.030200  0.000557  0.058544  0.000557  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "topic_distributions = [lda.get_document_topics(bow, minimum_probability=0) for bow in corpus]\n",
    "pdf = pd.DataFrame([[prob for _, prob in doc] for doc in topic_distributions], columns=[f\"Topic {i}\" for i in range(30)])\n",
    "\n",
    "pdf['tconst'] = df['tconst'].values  # Add tconst column\n",
    "pdf = pdf[['tconst'] + [f\"Topic {i}\" for i in range(30)]]  # Reorder columns\n",
    "\n",
    "print(pdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11cbd8aa-0ec4-4be9-9802-478019057d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.to_csv(\"lda_topics.tsv\", sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
